{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spam_bert_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPy2MVTaSkziNyQs+5+RZI5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asjnhy/NLP-Bert/blob/master/Bert-CNN-Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uk3xImKtlSfU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers\n",
        "!pip install konlpy\n",
        "!pip install -U imbalanced-learn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um2u8M-OlZ9v",
        "colab_type": "code",
        "outputId": "b90200eb-0f04-4af4-c0ff-a2ec5529d165",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertModel\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "from konlpy.tag import *"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxGrHPTzldmJ",
        "colab_type": "code",
        "outputId": "12fc994f-fb5c-4b73-b7e5-f613b514172a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CKY2FMUtmt0",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Dataset Preprocessing\n",
        "\n",
        "#####1. UnderSampling, training set = 200\n",
        "#####2. Insert [CLS] ,[SEP], Tokenize\n",
        "\n",
        "#####3. Input for Bert : input, attention_masks,  label\n",
        "#####4, split into training set(labeled), validation set(labeled)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTrTNapylkTB",
        "colab_type": "code",
        "outputId": "686b1fa3-3f76-4dac-81cb-36eb2317e211",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "train = pd.read_csv('/content/drive/My Drive/submission/0_Data/train.csv')\n",
        "test = pd.read_csv('/content/drive/My Drive/submission/0_Data/public_test.csv')\n",
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(295945, 4)\n",
            "(1626, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMhdvijeqfHi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "train_list = np.array(train.index).reshape(-1,1)\n",
        "X, y= RandomUnderSampler(random_state=0).fit_sample(train_list,train['smishing'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izRut0PzmQHm",
        "colab_type": "code",
        "outputId": "c3bead4c-398f-4016-fef9-4ab4d16778f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_smishing = []\n",
        "train_nonsmishing = []\n",
        "for a,b in zip(X,y):\n",
        "    if (b == 1):\n",
        "        train_smishing.append(a[0])\n",
        "    else: \n",
        "        train_nonsmishing.append(a[0])\n",
        "train=train.iloc[train_smishing+train_nonsmishing,:].reset_index(drop=True)\n",
        "print(len(train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "37406\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ug5Y4d7VsH87",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#스미싱 문자 100개, 스미싱 x 문자 100개만 추출 ---> 1000, 1000 수정 \n",
        "df1 = train[:1000]\n",
        "df2 = train[-1000:]\n",
        "train = pd.concat([df1,df2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeZmESn1q3G4",
        "colab_type": "code",
        "outputId": "8e40bdef-eb84-4b86-89ca-feae0f4e18cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>year_month</th>\n",
              "      <th>text</th>\n",
              "      <th>smishing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>2017-01</td>\n",
              "      <td>(광고)XXXBaXXX고객님들 뒤엔XXX 언제나 XXX새로운 마음가짐으로 새롭게 준...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>26</td>\n",
              "      <td>2017-01</td>\n",
              "      <td>(광고)XXX추가 XXX품   특판 안내문XXX 지점에서 취급하고 있는 여신 XXX...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>36</td>\n",
              "      <td>2017-01</td>\n",
              "      <td>(광고)XXX신용관리 XXX 알고 싶다나의 신용과 재무상태는 직접 관리해야지 누군가...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>45</td>\n",
              "      <td>2017-01</td>\n",
              "      <td>(광고)안녕하세요수신을 희망하지 않으실 경우에는 거부 라는 답장을 주시면 KISA ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>58</td>\n",
              "      <td>2017-01</td>\n",
              "      <td>(광고)한국citi bank 나의 대출한도와 금리는? 대출때문에 고민하고 있다거나 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id year_month                                               text  smishing\n",
              "0  10    2017-01  (광고)XXXBaXXX고객님들 뒤엔XXX 언제나 XXX새로운 마음가짐으로 새롭게 준...         1\n",
              "1  26    2017-01  (광고)XXX추가 XXX품   특판 안내문XXX 지점에서 취급하고 있는 여신 XXX...         1\n",
              "2  36    2017-01  (광고)XXX신용관리 XXX 알고 싶다나의 신용과 재무상태는 직접 관리해야지 누군가...         1\n",
              "3  45    2017-01  (광고)안녕하세요수신을 희망하지 않으실 경우에는 거부 라는 답장을 주시면 KISA ...         1\n",
              "4  58    2017-01  (광고)한국citi bank 나의 대출한도와 금리는? 대출때문에 고민하고 있다거나 ...         1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km9BdoielyxJ",
        "colab_type": "code",
        "outputId": "9b39ab6b-3162-4d67-a2d7-4fec7a89c25b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        }
      },
      "source": [
        "sentences = list(train[\"text\"])\n",
        "sentences[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['(광고)XXXBaXXX고객님들 뒤엔XXX 언제나 XXX새로운 마음가짐으로 새롭게 준비합니다.당행상품의 자격기준과 심사기준이 완화되어 상품에 대해 간단하게 상품정보 전달드립니다.수신을 희망하지 않으실 경우에는 거부 라는 답장을 주시면 KISA 수신거부 목록에 등록을 시켜 두번 다시 발송되지 않도록 조치를 취해드리겠습니다.신청방법:  XXX-XXX-XXX  터치하셔서 문자로 상담 또는 00시 00분 상담이라고 답장을 보내주시거나 전화를 주시면 친절하고 안전한 상담으로 도움드리겠습니다.카카오톡 상담서비스 시행중 citibankloan친구추가 후 상담신청이런 분들께 권해드립니다.1. 시중은행권에서 기존한도를 모두 사용 중이신 분.2. 기대출의 원리금 균등방식으로 인해 월 불입금액이 부담스러우신 분.3. 총 채무금액은 작으나 채무건수가 많아서 관리가 안 되시는 XXX고객님들께 말씀드립니다. 높은 금리 때문에 힘들다고 느끼셨을 때 대출이 필요하실 때 언제나XXX 고객님들 뒤에서 든든한 파트너로서 도와드리겠습니다.당행 상품특징1. 당행 거래가 없으셔도 진행가능.2. 시중은행권보다 높은 한도.3. 자체 등급으로 판단하므로 낮은신용자도 진행가능.4. 부채가 많다면 부채 통합상품으로 전환가능.5. 원리금 균등방식을 이자만 납입하는 만기일시로 전환가능.6. 가상 조회를 통해 한도 및 금리를 한 번에 확인가능.당행 상품안내1. 직장인전용 신용상품한도: 최대 1억 4000만 원까지.금리: 최저 2.97%자격: XXX은행 자체 등급과 기업 리스트에 따라 차등적용.2. 채무통합 전환상품한도: 연봉 대비 300%까지.금리: 최저 2.97%자격: XXX은행 자체 등급과 기업 리스트에 따라 차등적용.3. 새 희망 홀씨한도: 최대 2500만 원.금리: 8.68%12%자격: 연봉 4000만 원 이하 고객 대상으로 XXX 자체 등급에 따라(광고)XXX',\n",
              " '(광고)XXX추가 XXX품   특판 안내문XXX 지점에서 취급하고 있는 여신 XXX 드림론과 달리 여신영업부에서는  기존에 판매되고 있는 상품을 한도와 금리에 있어 파격적인 상품으로 한시적 판매하고 있습니다.상품상세내역-판매기간: 한도 소진 시까지(800억)-한도:기존 5천만원에서 1억원으로 상향조정-최고한도:월급여 8배에서 18배까지 상향조정-여XXX도:기존 타행부채가 연봉에 2배 이내면 추가가능-신용조회 시모바일 가조회 시스템으로 조회기록 없이 가능유무 확인.당 행 여신영업부에서 한시적으로 판매하는 상품XXX 고객님께서 메세지 꼭 저장해 놓으시고 자금 계획에 있어 도움을 드리고자 하오니 소중한 상담전화 부탁드립니다.감사합니다XXX 여신영업부 드림무료수신거부XXX-XXX-XXX(광고) XXX 추가 XXX',\n",
              " '(광고)XXX신용관리 XXX 알고 싶다나의 신용과 재무상태는 직접 관리해야지 누군가가 대신해주지 않습니다. 대출도 바로 알고 바로 쓰면 절대 나쁜 것이 아닙니다. 모든 분이 금융에 대해서 바로 알기를 원합니다. 조금만 관심을 가지신다면 건전한 신용과 재무상태가 될 것입니다.어렵지 않습니다. 제가 도와드릴 수 있도록 노력하겠습니다.신청방법: 문자로 상담이라는 답장을 주시거나 전화를 주시면 친절하고 안전한 상담으로 도와드리겠습니다.카카오톡 상담 서비스 시행 중 citibank55친구 추가 후 상담 신청XXX은행 대출상품안내1. 직장인 신용대출한도: 1억4000만 원까지.금리: 최저 2.97%자격: XXX은행 자체등급과 기업리스트에 따라 차등적용.2. 채무통합 전환대출한도: 연봉대비 300%까지.금리: 최저 2.97%자격: XXX은행 자체등급과 기업리스트에 따라 차등적용.3. 새희망홀씨 한도: 최대 2500만 원.금리: 8.68%12%자격: 연 소득 4000만 원 이하 고객 대상으로 XXX 자체등급에 따라 차등적용.XXX은행 상품의 특징1. 당사 거래가 전혀 없어도 대출 가능.2. 시중은행보다 높은 한도.3. 자체등급으로 판단하므로 저신용자도 대출 가능.4. 부채가 많다면 부채통합상품으로 전환 가능.5. 원리금 균등방식을 이자만 내는 만기일시로 전환 가능.6. 가상조회를 통해 한도 및 금리를 한 번에 확인 가능. 이런 분들께 권해드립니다.1. 이미 시중 은행권에서 대출한도를 모두 사용 중이신 분.2. 기존대출의 원리금 균등방식으로 인해 월납입금액이 부담스러우신 분.3. 총대출금액은 적으나 대출 건수가 많아서 관리가 안 되시는 분.4. 이제라도 대출로 인한 신용등급 관리 및 상승에 관심이 있으신 분.신청방법: 문자로 상담이라는 답장을 주시거나 전화를 주시면 친절하고 안전한 상담으로 도와드리겠습니다.카카오톡 상담 서비스 시행 중 c(광고)XXX  신용관리 XXX 알',\n",
              " '(광고)안녕하세요수신을 희망하지 않으실 경우에는 거부 라는 답장을 주시면 KISA 수신거부 목록에 등록을 시켜 두번 다시 발송되지 않도록 조치를 취해드리겠습니다.추가자금 이나 채무통합 상담안내 문자발송 하였습니다.XXX-XXX-XXX 담당:XXX팀장매우 바쁘신줄 알지만 3분만 시간을내주셔서 저의 글을 끝까지 읽어주시면 조금이나마 도움이 되실거라 판단되어 감히 글을 남깁니다.일전에 XXX금융 상담을 해드렸던 XXX 입니다.이런 연락들을 하루에도 몇번씩 받으실텐데 저까지 거들게되어 깊은 사과의 말씀부터 드리겠습니다.다름이 아니라 이번에 대출전문 컨설팅 회사로 이직을 했습니다.기존 XXX금융 근무할때는 세렉트론 한상품만 취급을 했지만이제는 전 금융권을 전부 가이드 해드릴수가 있기때문에 보다 나은 금융서비스를 제공해 드릴수가 있습니다.고객님 이용중이신 2금융권중 금리 높은 부분...추후 저금리추가자금채무통합기존정부상품1.햇살론새희망XXX드림론정부지원자금사잇돌보증재단 상품2.담보 아파트빌라상가건물토지등 상품 3.차량상품 또한 진행가능합니다 궁금한 사항 있으시면 언제든지 연락주시면 성심 성의껏 상담해 드리겠습니다.그리고 마지막으로 간혹 부채가 너무많이있으셔서 부채통합이 안되신다고 걱정을 하시는데 부채XXX 고객님 부채를 0 원으로 만들어 드린상태에서...이렇게 되면 당연히 등급한도가 최대로 살아나십니다.이런 상황에서 진행을 해드리는 부채통합 상품도 있으니 부채가 많으셔도 진행이 가능하십니다.부채통합 상품은 오히려 부채 많으신 분들이 이용하시는 상품입니다.위 내용중 하나라도 해당이 되시는분들은 언제든지 전화문자 연락주시면 정확한 상담을 해드리겠습니다.속는셈치고 연락한번 주시면 만족하실수 있도록 최선을 다하고 신뢰할수 있는 상담 도움드리겠습니다.많이 불편하셨다면 발신번호나 무료수신 거부 문자 주시면 수신거부 처리해드리겠습니다.불편하게 해드XXX 정말광고 XXX은행',\n",
              " '(광고)한국citi bank 나의 대출한도와 금리는? 대출때문에 고민하고 있다거나 높은이자에 허덕이고 있다면 2분만 시간을 내어 이문자에 집중할 시간입니다. 여러분의 악성대출을 상환할 수 있도록 도와드릴것을 약속드립니다. 1. 대출의 50%이상이 2금융권이신분들 2. 월급의 절반정도를 카드값으로 빠지시는분들 3. 부채의 대부분이 원리금 균등방식으로 상환하는분들 4. 등급이 낮아 은행권대출이 안된다고 판단하시는분들 ()내용을 읽어보시고한건이라도 해당이되신다면 꼭 상담이 필요하다고 생각듭니다. 저희가 모든 수단과 방법을 동원해 금리를 1%라도 낮춰드리고 금융에 관한 꿀팁을 알려드리겠습니다.   한국citi bank 직장인 상품 금리연2.82%(CD금리변동) 직장인기준(공무원외감업체대기업 우대) 한도1억4천만원까지  일반업체개인사업장 근로자도 진행가능 신용도와 상관없이  자체등급으로 판단   신청방법 문자로 상담 이라고 답장을 주시거나 전화를 주시면 정직하고 친절히 상담으로 도움드릴께요 신용 상담을 위한 신용조회는 등급에 영향을 미치지 않습니다.   카카오톡 신청방법 ID:citibank1 아이디검색후 친구추가후 상담이라는 카톡을 남겨주세요 빠르게 답변드리겠습니다.   부채통합대출 상품 자격조건:사대보험가능한 직장인 and 재직 1년이상(1년미만도  직군과 등급에 따라 가능할 수 있습니다 한도:연봉대비300%까지  금리:최저 3%(등급 차등적용)   부채통합대출의 장점 a)월 최대 85%정도 이자 절감(월100만원 이상) b)신용등급 상승 최대 13등급까지 상향 c)연봉대비(DTI) 280%까지(직군소득별 차등적용) d)건수를 최소화 시켜 관리가 용이하게!! e)추가 자금까지 저금리로 확보하게 해드립니다.  신청방법 문자로 상담 이라고 답장을 주시거나 전화를 주시면 정직하고 친절히 상담으로 도XXX',\n",
              " '(광고)다사다난했던 병신()년을 보내고 새로운 정유()년에는 늘 좋은 일과 뜻하시는 소망을 이루시는 새해가 되시기 바랍니다.저희 XXX과 기존 거래가 없으셨던  4대보험적용 되시는 직장인분들께도 새로운 금리체계로 보다 많은 은행의 혜택을 드리고자 직장인 신용 대출 상품을 출시하였습니다.지금 사용중인 신용대출을 잘 확인하시고 잘못된 상품을 사용중이라면 심사숙고 하셔서 바꿔보시는게 어떠실까요?  신용대출상품 - 최저금리 3.18% - 월급여의 최고 21배까지 한도 확대.(최고 1억2천가능) - 연봉의 2배까지 신용부채가 있어도 가능. - 신용조회 기록 남지 않음. - 1억2천 한도내에서 언제든 대출가능. - 여러 건의 부채를 통합 하실수 있는 기회. - 타사 신용대출 금리와 비교해 보시면 좋으세요. 1천만원 대출시 매월 평균 이자 13000원납부 (5년기준) (원금이자 한달 18만원 정도 부과됨.) 카드론 및 XXX XXX 상품 이용시는 분은 추천해 드립니다.꼭 이용을 하시라고 문자를 드리는게 아닙니다. 궁금하신 내용이 있으시거나 혹은 상담을 받아야 겠다고 느끼시거나 추가로 필요하시거나여러 건의 부채 통합을 원하시거나 한달 월불입금이 많으셔서 계속 현금서비스나 카드론 대출이 늘어난다고 생각이 드시면 주저 없이 연락주시기 바랍니다.특히 XXX이나 XXX 4금융권을 쓰고계신분들은 꼭연락부탁드립니다.30%대정도되시는 금리를 10%대로 갈아타셔도 엄청난 이자 절감을하실수있으십니다예를들어 2000만원을 (2금융권4금융권)쓰고계신다면 30%대에서 10%대로만 바꾸신다면 2000만원에서 20%로1년에 400만원을 이자절감하실수 있으시고 평균 5년짜리 상품을쓰신다는가정하에 5년동안 2000만원을절감할수 있는기회가 되시니 전화주셔서 저렴한 금리로 부채통합하시길 바랍니다내선전화가 통화중이거나 부재중일경우 H: XXX-XXX-XXX(상담사: XXX)로상담새해 복 많이 받으세요',\n",
              " '(광고)한국 (XXX XXX)2분의 시간만 투자하시면 월200만원 SAVE(절감)되실껍니다.비싼 이자를 전환하고자 하시는 분매월 나가고있는 불입금을 줄이려고 하는분여러건을 사용중이고 통합을 원하시는 분적금및 보험을 늘려 빨리 돈을 모으고 싶으신분마지막으로 신용등급을 올리고자 하시는 분()내용을 하고자 하시는 분들 꼭 읽어보시고 연락을 주시면 저희가 모든 수단과 방법을 동원해 도움을 드릴것을 약속합니다.XXX XXX직장인 안내금리 연2.82%(CD금리변동)직장인기준(공무원외감업체대기업 우대)한도 1억4천만원까지 일반업체개인사업장 근로자도 진행가능신용도와 상관없이  자체등급으로 판단신청방법:문자로 상담 이라고 답장을 주시거나 전화를 주시면 정직하고 친절히 상담으로 도움드릴께요신용상담을 위한 신용조회는 등급에 영향을 미치지 않습니다  카카오톡 신청방법ID:citibank1 아이디검색후 친구추가후 상담이라는 카톡을 남겨주세요 빠르게 답변드리겠습니다.부채통합대출 상품안내자격조건:사대보험가능한 직장인 and 재직 1년이상(1년미만도 직군과 등급에 따라 가능할 수 있습니다한도:연봉대비300%까지 금리:최저 3%(등급 차등적용) (부채)통 합 상 품 의 요 약 연소득대비 최대300%이내신용등급 7등급이내의 직장인이면카드론현금서비스 사용이 잦은 분들원리금균등방식을 이자만내는 방식으로 전환부채과다로인해 추가진행이 어렵다면 통합해드리겠습니다최근 6개월간 연체사실이 있다면 진행이 안됩니다신청방법:문자로 상담 이라고 답장을 주시거나 전화를 주시면 정직하고 친절히 상담으로 도움드릴께요신용에 대한 기본적인 상식과 지식을 알아야 하는 시대입니다. 최소한의 지식을 직접 알아야 금전적 손해를 보는 일이 없습니다건수 과다시-대출 건수를 줄이시면 신용등급이 상승합니다거치상품 만기-대출연장으XXX',\n",
              " '(광고)한국citi bank나의 대출한도와 금리는?대출때문에 고민하고 있다거나 높은이자에 허덕이고 있다면 2분만 시간을 내어 이문자에 레알 집중할 시간입니다.여러분의 악성대출을 상환할 수 있도록 도와드리겠습니다.1. 대출의 50%이상이 2금융권이신분들2. 월급의 절반정도를 카드값으로 빠지시는분들3. 부채의 대부분이 원리금 균등방식으로 상환하는분들4. 등급이 낮아 은행권대출이 안된다고 판단하시는분들()내용을 읽어보시고한건이라도 해당이되신다면 꼭 상담이 필요하다고 생각듭니다. 저희가 모든 수단과 방법을 동원해 금리를 최대한 낮춰드리고 금융에 관한 꿀tip 을 알려드리겠습니다.신용카드 남용은 가계경제에 위협이 됩니다.한국citi bank 직장인 상품금리연2.82%(CD금리변동)직장인기준(공무원외감업체대기업 우대)한도1억4천만원까지일반업체개인사업장 근로자도 진행가능신용도와 상관없이  자체등급으로 판단신청방법문자로 상담 이라고 답장을 주시거나 전화를 주시면 정직하고 친절히 상담으로 도움드릴께요신용 상담을 위한 신용조회는 등급에 영향을 미치지 않습니다.금융에 대한 기본적인 지식과 상식을 알아야 건전한 재무상태를 만들 수 있습니다.카카오톡 신청방법ID:citibank12 아이디검색후 친구추가후 상담이라는 카톡을 남겨주세요 빠르게 답변드리겠습니다.부채통합대출 상품자격조건:사대보험가능한 직장인 and 재직 1년이상(1년미만도  직군과 등급에 따라 가능할 수 있습니다한도:연봉대비300%까지금리:최저 3%(등급 차등적용)부채통합대출의 장점a)월 최대 85%정도 이자 절감(월100만원 이상)b)신용등급 상승 최대 13등급까지 상향c)연봉대비(DTI) 280%까지(직군소득별 차등적용)d)건수를 최소화 시켜 관리가 용이하게!!e)추가 자금까지 저금리로 확보하게 해드립니다.신청방법문자로 상담 이라고 답장을 주시거나 전화를 주시면 정직하고 친절히 상담으로 도움드릴께요(햇)(살)(론)새희망 홀씨안내최대 3000만원까지연 20%이상의 악성부채를 6개월 이상사용중인분연 10%대의 낮은금리로수신을 희망하지 않으시면 거부라는 답장 또는 하단부에 수신거부번호로 연락주시면 바로 조치하도록 하겠습니다무료수신거부 XXX-XXX-XXXciti bank',\n",
              " '(광고)신용협동조합 안내XXX세요하루하루 힘든업무와 스트레스에 고생많으십니다여유시간을 내어 읽어 주신다면 도움이 되실거라 생각되어 안내장을 보내드립니다신협대상 - 연소득 2천 이상금리 - 최저 4.24%  9.89%기간 - 최대 10년 거치 만기상품으로 이자만 납입하시거나 5년분할상환 중 자유선택가능1 담보대출은 대출한도에 영향을주지않으므로 담보대출이 과다하여도 대출가능2 카드론2금융대출이 있으셔도 대환대출로 진행가능3 대출건수현금서비스 금액이 많아도 예외건으로 진행가능4 신용등급 17등급 진행가능많은 직장인분들이 바쁘셔서 혹은 시중은행 가계대출(신용대출)이 제한되면서 현금서비스 및 고금리의 2금융권상품(카드론XXXXXX)을 많이들 사용하고 계십니다XXX 고객님들을 낮은 금리의 전환대출 및 부채통합을 도와드리고 있습니다(분산된 부채 통합시 신용등급 상승 및 매월 내시는 불입금액에 대한 부담감소 이자비용의 절감)이자만 납입시)5000만원 신청시 매월 250417원으로 이용가능 합니다5년분할 납입시)5000만원 신청시 매월 966873원(원금이자)으로 이용가능 합니다이번 기회에 은행권 저금리상품으로 전환해 보시기 바랍니다홍보성 문자이나 필요한 한분 한분에게 도움이 되고자 합니다신청방법상담 가능 시간.성함.으로 문자예약.또는 전화주시면 상담가능하십니다감사합니다.은행권대환 추가자금신협 수탁법인상담전화XXX-XXX-XXX해당이 되지 않으시거나 거부를 원하시는 분들은 거부라고 회신하여 주신다면 재발송 않도록 하겠습니다 번호의 오류나 전산의 실수가 있을 수 있사오니 양해 부탁드립니다무료수신거부XXX-XXX-XXX(광고)신용협동조합 안내XXX',\n",
              " '(광고)신협안녕하십니까 하루하루 힘들고 스트레스 받는 대한민국에서 고생이 많으신데 이렇게 문자로 귀찮게 해드려 정말 죄송한 마음입니다. 잠시 시간을 내시어 읽어주신다면 도움이 되실거라 생각하고 안내문을 보내드립니다.정부지원 신용대출 안내대상- 연소득 2천이상금리- 최저 4.38%  9.87%기간- 최대 10년 거치 만기상품으로 이자 납입가능 5년분할상환 중 택1. 담보대출은 대출한도에 영향을 주지 않으므로 담보대출이 과다하여도 가능2. 카드론2금융대출 대환 대출로 진행가능3. 대출건수현금서비스 금액이 많아도 예외 건 진행가능4. 신용등급 17등급 진행가능 8등급 예외 건 진행가능 많은 직장인 사업자 분들이 바쁘시거나 금융권 대출의 가이드를 잘 알지 못해서 대출을 이용하실 때 고금리 상품을 이용하시거나 시중은행 가계대출이 제한되면서 2금융권이나 대부를 이용하는 경우가 많습니다.XXX 고객님들에게 낮은 금리의 전화대출 부채통합을 도와드리고 있습니다.(분산된 부채 통합시 신용등급 상승 및 매월 내시는 불입금액에 대한 부담을 줄이고 이자를 절감할 수 있습니다.)(이자만 납입시)5000만원 신청시 매월 250417원으로 이용가능 합니다(5년분할 납입시)5000만원 신청시 매월 966873원(원금이자)으로 이용가능 합니다.이번 기회에 필요한 분이 계신다면 저금리상품으로 전환해 보시기 바랍니다.광고성 문자로 불편하게 해드려 죄송합니다. 다만 필요한 분이 계시다면 꼭 도움이 되어 드리고자 합니다.신청방법상담 가능시간과 성함을 문자로 남겨주셔도 되고 전화주셔도 상담신청이 가능합니다.감사합니다.불법대출 보이스 피싱안내대출진행 시 절대 수수료를 요구하지 않습니다.특히 대출진행 전이나 후에 수수료를 요구하거나 대출 가조회 전에 서류부터 요구하는 것은 일단 의심하시고 진행전에 확인하셔야 합니다.은행권대환 추가자금신협 수탁법인상담전화XXX-XXX-XXX해당이 되지 않으시거나 거부를 원하시는 분들은 거부라고 회신하여 주신다면 재발송 않도록 하겠습니다. 번호의 오류나 전산상의 실수가 있을 수 있사오니 양해 부탁드립니다무료거부XXX-XXX-XXX안내드립니다']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImWh42AHrPK-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 라벨 추출\n",
        "labels =list(train['smishing'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxapbM3dn83y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#csv 파일 추가\n",
        "removeword=['[Web발신]', \"\\n\", \"\\r\",'X',\n",
        "            '.', '을', '를', '이', '가', '-', '(', ')', ':', '!', '?', ')-', '.-', 'ㅡ','..', '.(', '은', '는','0','1','2','3','4','5','6','7','8','9']\n",
        "\n",
        "def stopword(s): \n",
        "    if removeword:\n",
        "        for word in removeword:\n",
        "            s = s.replace(word,\"\")\n",
        "    return s\n",
        "\n",
        "def cut(s):\n",
        "    if len(s) > 30: \n",
        "        return s[:30]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txKoX7O_neLs",
        "colab_type": "code",
        "outputId": "cee445b7-974c-41c8-cdd9-e0586f748cbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "sentences_preprocess = list(map(lambda sen: cut(stopword(str(sen))),sentences))\n",
        "sentences_ = list(map(lambda sen:'[CLS]' + str(sen) + '[SEP]' , sentences_preprocess))\n",
        "sentences_[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]광고Ba고객님들 뒤엔 언제나 새로운 마음짐으로 새롭게 [SEP]',\n",
              " '[CLS]광고추 품   특판 안내문 지점에서 취급하고 있 여신 [SEP]',\n",
              " '[CLS]광고신용관리  알고 싶다나의 신용과 재무상태 직접 관리[SEP]',\n",
              " '[CLS]광고안녕하세요수신 희망하지 않으실 경우에 거부 라 답장[SEP]',\n",
              " '[CLS]광고한국citi bank 나의 대출한도와 금리 대출때문[SEP]',\n",
              " '[CLS]광고다사다난했던 병신년 보내고 새로운 정유년에 늘 좋 [SEP]',\n",
              " '[CLS]광고한국  분의 시간만 투자하시면 월만원 SAVE절감되[SEP]',\n",
              " '[CLS]광고한국citi bank나의 대출한도와 금리대출때문에 [SEP]',\n",
              " '[CLS]광고신용협동조합 안내세요하루하루 힘든업무와 스트레스에 [SEP]',\n",
              " '[CLS]광고신협안녕하십니까 하루하루 힘들고 스트레스 받 대한민[SEP]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6ry0Xb0F_Hn",
        "colab_type": "text"
      },
      "source": [
        "*WordPiece Tokenizer* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IM1MhIGemu6-",
        "colab_type": "code",
        "outputId": "6e548d63-91a4-4d3d-ac9f-55313e17466b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# BERT의 토크나이저로 문장을 토큰으로 분리(wordpiece)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False) #버트 워드피스 토크나이저말고 딴거! \n",
        "tokenized_texts = [tokenizer.tokenize(sen) for sen in sentences_]\n",
        "\n",
        "print(sentences_[0])\n",
        "print(tokenized_texts[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS]광고Ba고객님들 뒤엔 언제나 새로운 마음짐으로 새롭게 [SEP]\n",
            "['[CLS]', '광', '##고', '##B', '##a', '##고', '##객', '##님', '##들', '뒤', '##엔', '언', '##제', '##나', '새로운', '마', '##음', '##짐', '##으로', '새', '##롭', '##게', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZpSjzqfuwxb",
        "colab_type": "code",
        "outputId": "f84534aa-8d80-431b-a446-6370a8f3079b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(tokenized_texts[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZsiBaUfW4ou",
        "colab_type": "text"
      },
      "source": [
        "*attention_mask is not required for BertModel*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dTW6wU5tgeP",
        "colab_type": "code",
        "outputId": "5baadd00-8c83-4d8a-fe75-deabbbc3ace5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "#bert 인풋 형식 맞게 input_ids 만들어줌 \n",
        "#input_ids : embedding + padding \n",
        "max_len = 0\n",
        "for txt in tokenized_texts:\n",
        "    if max_len < len(txt): \n",
        "        max_len = len(txt)\n",
        "\n",
        "\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(tokens) for tokens in tokenized_texts]\n",
        "input_ids = pad_sequences(input_ids, maxlen = max_len, dtype = 'long', truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print(max_len)\n",
        "print(input_ids[0])\n",
        "print(input_ids.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "[   101   8903  11664  11274  10113  11664 118617 108578  27023   9109\n",
            "  86933   9548  17730  16439  39773   9246  32158 119231  11467   9415\n",
            " 118884  14153    102      0      0      0      0      0      0      0\n",
            "      0      0]\n",
            "(2000, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OU1z2-h7vxE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # attention_mask : 1 if not padded, 0 if padded \n",
        "\n",
        "# def masking(d):\n",
        "#     masklist = []\n",
        "#     for e in d:\n",
        "#         if float(e)!=0:\n",
        "#             masklist.append(1)\n",
        "#         else:\n",
        "#             masklist.append(0)\n",
        "#     return masklist\n",
        "# attention_mask = list(map(lambda seq : masking(seq), input_ids))\n",
        "\n",
        "\n",
        "# print(attention_mask[0])        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FkGYQMlxbV_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train, test split \n",
        "train_id, validation_id,train_label, validation_label = train_test_split(input_ids, labels, test_size = 0.2, random_state = 1010, shuffle= True)\n",
        "# train_att_mask, validation_att_mask, _, _ = train_test_split(attention_mask, input_ids, test_size = 0.1, random_state = 1010, shuffle= False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ePokdlq-rai",
        "colab_type": "code",
        "outputId": "11c2ff55-54bb-4ade-bae1-e484c67fd1a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "print(train_label)\n",
        "print(validation_label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0]\n",
            "[1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wplrpHuyIfc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_id = torch.tensor(train_id)\n",
        "validation_id = torch.tensor(validation_id)\n",
        "train_label = torch.tensor(train_label)\n",
        "validation_label = torch.tensor(validation_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wO7aJ957zi6-",
        "colab_type": "code",
        "outputId": "cf712ae9-a973-4394-975c-d73b0a4c9fdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "print(train_id[53])\n",
        "print(train_label[0])\n",
        "print(validation_id[0])\n",
        "print(validation_label[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([   101,   8903,  11664,   9730,  13890,  40032, 119184,  14871,  52951,\n",
            "          9521,  31605,   8903,  11664,   9297,  13764,  58303,  48345,  42608,\n",
            "          9318, 119022,  25387, 119219,    102,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0])\n",
            "tensor(0)\n",
            "tensor([   101,   8903,  11664,  11102,  20479,   8927,   9642,  28911,   9367,\n",
            "         10459,   9485,  18784,  19105,   9881,  13764,  35506,  14040,  14867,\n",
            "          9249,   9087, 119169,   9098,  31503,    102,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0])\n",
            "tensor(1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yH9Z_PWaZNaR",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "*BertModel*\n",
        "\n",
        "*( \"The bare Bert Model transformer outputting raw hidden-states without any specific head on top.\")*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMkHa71JXww0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_model = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
        "\n",
        "with torch.no_grad():\n",
        "    x_train = bert_model(train_id)[0]\n",
        "    x_val = bert_model(validation_id)[0]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGLH_1CxZ4W-",
        "colab_type": "code",
        "outputId": "94d886e4-60c4-4efc-9f51-f3c191a566a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "y_train = train_label.float().unsqueeze(1)\n",
        "y_val = validation_label.float().unsqueeze(1) \n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1600, 32, 768])\n",
            "torch.Size([1600, 1])\n",
            "torch.Size([400, 32, 768])\n",
            "torch.Size([400, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGk-A-393vrR",
        "colab_type": "text"
      },
      "source": [
        "## Dataset Preprocessing - Testing set \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvGGFwtt3fPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sentences = test['text']\n",
        "\n",
        "# sentences_preprocess = list(map(lambda sen: cut(stopword(str(sen))),sentences))\n",
        "# sentences_ = list(map(lambda sen:'[CLS]' + str(sen) + '[SEP]' , sentences_preprocess))\n",
        "\n",
        "# tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
        "# tokenized_texts = [tokenizer.tokenize(sen) for sen in sentences_]\n",
        "\n",
        "# max_len = 22\n",
        "# input_ids = [tokenizer.convert_tokens_to_ids(tokens) for tokens in tokenized_texts]\n",
        "# input_ids = pad_sequences(input_ids, maxlen = max_len, dtype = 'long', truncating=\"post\", padding=\"post\")\n",
        "\n",
        "\n",
        "# print(sentences_[0])\n",
        "# print(tokenized_texts[0])\n",
        "# print(input_ids[0])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiX2qWTR37c0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test_input = torch.tensor(input_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJCzgSLc6iJE",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfK-yPxhcZSi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, embed_num, embed_dim, class_num, kernel_num, kernel_sizes, dropout, static):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        V = embed_num\n",
        "        D = embed_dim\n",
        "        C = class_num\n",
        "        Co = kernel_num\n",
        "        Ks = kernel_sizes\n",
        "        \n",
        "        self.static = static\n",
        "        self.embed = nn.Embedding(V, D)\n",
        "        self.convs1 = nn.ModuleList([nn.Conv2d(1, Co, (K, D)) for K in Ks]) \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc1 = nn.Linear(len(Ks) * Co, C)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.static:\n",
        "            x = Variable(x)\n",
        "\n",
        "        x = x.unsqueeze(1)  # (N, Ci, W, D)\n",
        "\n",
        "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1]  # [(N, Co, W), ...]*len(Ks)\n",
        "\n",
        "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N, Co), ...]*len(Ks)\n",
        "\n",
        "        x = torch.cat(x, 1)\n",
        "        x = self.dropout(x)  # (N, len(Ks)*Co)\n",
        "        logit = self.fc1(x)  # (N, C)\n",
        "        output = self.sigmoid(logit)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tffqzNOZczvS",
        "colab_type": "code",
        "outputId": "e17e0c85-c7a3-42a9-b100-7e8f5c1f57b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "embed_num = x_train.shape[1]\n",
        "embed_dim = x_train.shape[2]\n",
        "class_num = y_train.shape[1]\n",
        "kernel_num = 3\n",
        "kernel_sizes = [2, 3, 4]\n",
        "dropout = 0.5\n",
        "static = True\n",
        "print(embed_num)\n",
        "print(embed_dim)\n",
        "print(class_num)\n",
        "print(kernel_num)\n",
        "print(kernel_sizes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "768\n",
            "1\n",
            "3\n",
            "[2, 3, 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdSNKuM4dQqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = CNN(\n",
        "    embed_num=embed_num,\n",
        "    embed_dim=embed_dim,\n",
        "    class_num=class_num,\n",
        "    kernel_num=kernel_num,\n",
        "    kernel_sizes=kernel_sizes,\n",
        "    dropout=dropout,\n",
        "    static=static,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXJvOICedR9p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_epochs = 10\n",
        "batch_size = 10\n",
        "lr = 0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss_fn = nn.BCELoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36L0oz4DdWqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_batch_data(x, y, batch_size):\n",
        "    i, batch = 0, 0\n",
        "    for batch, i in enumerate(range(0, len(x) - batch_size, batch_size), 1):\n",
        "        x_batch = x[i : i + batch_size]\n",
        "        y_batch = y[i : i + batch_size]\n",
        "        yield x_batch, y_batch, batch\n",
        "    if i + batch_size < len(x):\n",
        "        yield x[i + batch_size :], y[i + batch_size :], batch + 1\n",
        "    if batch == 0:\n",
        "        yield x, y, 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZN719DEdfco",
        "colab_type": "code",
        "outputId": "6c35f952-31a9-4331-a798-768786a8cf81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "train_losses, val_losses = [], []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    start_time = time.time()\n",
        "    train_loss = 0\n",
        "    train_accuracy = 0\n",
        "    test_accuracy = 0\n",
        "    batch_train_accuracy = []\n",
        "    batch_test_accuracy = []\n",
        "    model.train(True)\n",
        "    for x_batch, y_batch, batch in generate_batch_data(x_train, y_train, batch_size):\n",
        "        y_pred_label = []\n",
        "        y_pred = model(x_batch)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        y_pred_label = np.where(y_pred>=0.5, 1, 0)\n",
        "        batch_train_accuracy.append(accuracy_score(y_pred_label,y_batch.numpy()))\n",
        "\n",
        "        loss = loss_fn(y_pred,y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    \n",
        "    train_accuracy = sum(batch_train_accuracy) / batch \n",
        "    train_loss /= batch\n",
        "    train_losses.append(train_loss)\n",
        "    elapsed = time.time() - start_time\n",
        "\n",
        "\n",
        "    \n",
        "    model.eval() # disable dropout for deterministic output\n",
        "    with torch.no_grad(): # deactivate autograd engine to reduce memory usage and speed up computations\n",
        "        val_loss, batch = 0, 1\n",
        "\n",
        "        for x_batch, y_batch, batch in generate_batch_data(x_val, y_val, batch_size):\n",
        "            y_pred_label = []\n",
        "            y_pred = model(x_batch)\n",
        "            loss = loss_fn(y_pred, y_batch)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            \n",
        "            y_pred_label = np.where(y_pred>=0.5, 1, 0)\n",
        "            batch_test_accuracy.append(accuracy_score(y_pred_label,y_batch.numpy()))\n",
        "            \n",
        "        val_loss /= batch\n",
        "        val_losses.append(val_loss)\n",
        "        test_accuracy = sum(batch_test_accuracy)/ batch\n",
        "\n",
        "    print(\n",
        "        \"Epoch %d Train loss: %.2f. Validation loss: %.2f. Elapsed time: %.2fs. Accuracy in Training: %.3f. Accuracy in Testing : %.3f\"\n",
        "        % (epoch + 1, train_losses[-1], val_losses[-1], elapsed, train_accuracy, test_accuracy)\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Train loss: 0.32. Validation loss: 0.12. Elapsed time: 2.49s. Accuracy in Training: 0.863. Accuracy in Testing : 0.965\n",
            "Epoch 2 Train loss: 0.17. Validation loss: 0.08. Elapsed time: 2.51s. Accuracy in Training: 0.939. Accuracy in Testing : 0.977\n",
            "Epoch 3 Train loss: 0.14. Validation loss: 0.06. Elapsed time: 2.37s. Accuracy in Training: 0.951. Accuracy in Testing : 0.975\n",
            "Epoch 4 Train loss: 0.10. Validation loss: 0.05. Elapsed time: 2.29s. Accuracy in Training: 0.967. Accuracy in Testing : 0.980\n",
            "Epoch 5 Train loss: 0.11. Validation loss: 0.05. Elapsed time: 2.37s. Accuracy in Training: 0.963. Accuracy in Testing : 0.980\n",
            "Epoch 6 Train loss: 0.09. Validation loss: 0.07. Elapsed time: 2.34s. Accuracy in Training: 0.963. Accuracy in Testing : 0.972\n",
            "Epoch 7 Train loss: 0.09. Validation loss: 0.05. Elapsed time: 2.36s. Accuracy in Training: 0.968. Accuracy in Testing : 0.977\n",
            "Epoch 8 Train loss: 0.08. Validation loss: 0.05. Elapsed time: 2.29s. Accuracy in Training: 0.967. Accuracy in Testing : 0.980\n",
            "Epoch 9 Train loss: 0.09. Validation loss: 0.06. Elapsed time: 2.32s. Accuracy in Training: 0.971. Accuracy in Testing : 0.980\n",
            "Epoch 10 Train loss: 0.06. Validation loss: 0.05. Elapsed time: 2.31s. Accuracy in Training: 0.968. Accuracy in Testing : 0.980\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0QjqQ0m4Eqh",
        "colab_type": "code",
        "outputId": "140800a0-8e10-414a-f97a-8e7b63c808c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "plt.plot(train_losses, label=\"Training loss\")\n",
        "plt.plot(val_losses, label=\"Validation loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Losses\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Losses')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guRyg1Oy9iM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/pytorch/captum.git\n",
        "!cd captum; pip install -e ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFm-T9t9_Ek7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "import torch\n",
        "\n",
        "from captum.attr import IntegratedGradients\n",
        "from captum.attr import LayerConductance\n",
        "from captum.attr import NeuronConductance\n",
        "\n",
        "token_reference = TokenReferenceBase(reference_token_idx = input_ids)\n",
        "lig = LayerIntegratedGradients(model, model.embedding)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfersPyB_a-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}