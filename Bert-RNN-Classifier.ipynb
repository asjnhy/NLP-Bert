{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spam_bert_rnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asjnhy/NLP-Bert/blob/master/spam_bert_rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxGrHPTzldmJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5w3wC31u_8ug",
        "colab_type": "code",
        "outputId": "178d7812-ffa3-4959-8ba8-077c4d8a1167",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git \n",
        "!cd Mecab-ko-for-Google-Colab;bash install_mecab-ko_on_colab190912.sh  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Mecab-ko-for-Google-Colab' already exists and is not an empty directory.\n",
            "Installing konlpy.....\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.6/dist-packages (0.5.2)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.17.5)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.4.3)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (3.8.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.7.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.12.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.21.0)\n",
            "Requirement already satisfied: PySocks>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2020-02-12 11:44:05--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 18.205.93.1, 18.205.93.0, 18.205.93.2, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|18.205.93.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=vWCVc9GXcVFfZVmU3cbyZ5Xe9MQ%3D&Expires=1581509253&AWSAccessKeyId=AKIAIQWXW6WLXMB5QZAQ&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22 [following]\n",
            "--2020-02-12 11:44:05--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=vWCVc9GXcVFfZVmU3cbyZ5Xe9MQ%3D&Expires=1581509253&AWSAccessKeyId=AKIAIQWXW6WLXMB5QZAQ&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.8.52\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.8.52|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz.1’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2020-02-12 11:44:06 (17.0 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz.1’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2020-02-12 11:44:20--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 18.205.93.1, 18.205.93.0, 18.205.93.2, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|18.205.93.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=MYq%2BBvEkur7DYjUyQyMR%2FaLDZF4%3D&Expires=1581509660&AWSAccessKeyId=AKIAIQWXW6WLXMB5QZAQ&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22 [following]\n",
            "--2020-02-12 11:44:20--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=MYq%2BBvEkur7DYjUyQyMR%2FaLDZF4%3D&Expires=1581509660&AWSAccessKeyId=AKIAIQWXW6WLXMB5QZAQ&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.206.179\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.206.179|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz.1’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  81.5MB/s    in 0.6s    \n",
            "\n",
            "2020-02-12 11:44:21 (81.5 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz.1’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "apt-get update\n",
            "apt-get upgrade\n",
            "apt install curl\n",
            "apt install git\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
            "Done\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKAeddWR6-m8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from konlpy.tag import Mecab\n",
        "mecab = Mecab()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFsn9imp7CrN",
        "colab_type": "code",
        "outputId": "74804e4f-adb6-4658-a1d2-4b438067eff8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = '동동이안녕'\n",
        "mecab.morphs(a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['동동', '이', '안녕']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uk3xImKtlSfU",
        "colab_type": "code",
        "outputId": "bd408ee5-3a2a-48b2-ee4d-9d31b2a67bd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 774
        }
      },
      "source": [
        "!pip install transformers\n",
        "!pip install konlpy\n",
        "!pip install -U imbalanced-learn"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: tokenizers==0.0.11 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.11)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.10)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.10 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.10)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.2)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.10->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.10->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.6/dist-packages (0.5.2)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.17.5)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (3.8.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.7.1)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.12.0)\n",
            "Requirement already satisfied: PySocks>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.21.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already up-to-date: imbalanced-learn in /usr/local/lib/python3.6/dist-packages (0.6.1)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.22 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (0.22.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (0.14.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.17 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.17.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um2u8M-OlZ9v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertModel\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "from konlpy.tag import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CKY2FMUtmt0",
        "colab_type": "text"
      },
      "source": [
        "## - Overall Process \n",
        "\n",
        "#####1. UnderSampling, training set = 200 ----> Not used for this code \n",
        "#####2. Insert [CLS] ,[SEP], Tokenize\n",
        "\n",
        "#####3. Input for Bert : input, attention_masks,  label\n",
        "#####4, split into training set(labeled), validation set(labeled)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBIRxxaXJZEk",
        "colab_type": "text"
      },
      "source": [
        "##1. Import Dataset & Stopword set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTrTNapylkTB",
        "colab_type": "code",
        "outputId": "643538b5-5c56-4146-9a30-9fafd5c727a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "source": [
        "## 경로 설정 \n",
        "os.chdir('/content/drive/My Drive/capstone')\n",
        "train = pd.read_csv('sample3000.csv')\n",
        "train.rename(columns = {'Unnamed: 1':'text',\n",
        "                        'Unnamed: 2': 'smishing'}, inplace = True)\n",
        "del train['train_new (1)']\n",
        "train.drop([0], inplace = True)\n",
        "train['smishing'] = train['smishing'].apply(pd.to_numeric,errors = 'coerce')\n",
        "# train['text'] = train['text'].apply(lambda x : \"\".join(x)) \n",
        "# train['text'] = astype(train['text'],'str').dtypes\n",
        "print(train.dtypes)\n",
        "\n",
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text        object\n",
            "smishing     int64\n",
            "dtype: object\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>smishing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>항상거래감사드립니다 봄햇살느끼며 오늘도 행복한하루 보내세요-과장</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>고객님의소중한거래감사드립니다 매우동의부탁드립니다.차장</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>밝은 미소로 사랑 가득한 하루 보내세요 -벤처밸리 XXX드림-</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>은행활짝 핀 웃음으로 행복한 한 주 되세요 XXX지점</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>바쁘신 와중에 내점 해 주셔서 감사드립니다 설문조사 오면 매우동의라고 해주세요</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          text  smishing\n",
              "1          항상거래감사드립니다 봄햇살느끼며 오늘도 행복한하루 보내세요-과장         0\n",
              "2                고객님의소중한거래감사드립니다 매우동의부탁드립니다.차장         0\n",
              "3           밝은 미소로 사랑 가득한 하루 보내세요 -벤처밸리 XXX드림-         0\n",
              "4                은행활짝 핀 웃음으로 행복한 한 주 되세요 XXX지점         0\n",
              "5  바쁘신 와중에 내점 해 주셔서 감사드립니다 설문조사 오면 매우동의라고 해주세요         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfoXu7El_6nh",
        "colab_type": "code",
        "outputId": "fce6779d-f9ad-4afb-f148-df48fa5c5ce6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "sw = pd.read_csv('stopword_mecab.csv')\n",
        "removewords = []\n",
        "for i in sw['XXX']:\n",
        "    removewords.append(str(i))\n",
        "\n",
        "removewords.append('X')\n",
        "removewords.append('XX')\n",
        "removewords.append('XXX')\n",
        "removewords.append('[Web발신]')\n",
        "removewords.append('광고')\n",
        "\n",
        "\n",
        "print(sw.dtypes)\n",
        "removewords[:10]\n",
        "\n",
        "\n",
        "# removewords=['[Web발신]', \"\\n\", \"\\r\",'X',\n",
        "#             '.', '을', '를', '이', '가', '-', '(', ')', ':', '!', '?', ')-', '.-', 'ㅡ','..', '.(', '은', '는','0','1','2','3','4','5','6','7','8','9']\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XXX    object\n",
            "dtype: object\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['은행', '감사', '팀장', '입니다', '지점', '과장', '(', ')', '올림', '드림']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SS-GgFeR7OnV",
        "colab_type": "code",
        "outputId": "6d9b4a58-0182-4c24-b084-8297b44945f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "train['smishing'].value_counts().head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    1500\n",
              "0    1500\n",
              "Name: smishing, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeZmESn1q3G4",
        "colab_type": "code",
        "outputId": "d15da627-4ad1-42a9-d55a-7eae512d546c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "print(train['text'][train['smishing']==0].head())\n",
        "print(train['text'][train['smishing']==1].head())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1            항상거래감사드립니다 봄햇살느끼며 오늘도 행복한하루 보내세요-과장\n",
            "2                  고객님의소중한거래감사드립니다 매우동의부탁드립니다.차장\n",
            "3             밝은 미소로 사랑 가득한 하루 보내세요 -벤처밸리 XXX드림-\n",
            "4                  은행활짝 핀 웃음으로 행복한 한 주 되세요 XXX지점\n",
            "5    바쁘신 와중에 내점 해 주셔서 감사드립니다 설문조사 오면 매우동의라고 해주세요\n",
            "Name: text, dtype: object\n",
            "1501    (광고)(내용)무담보.신상품.출시안내본상품은 서민지원대출로 정부에서 지원하고 은행에...\n",
            "1502    (광고)1.부득이하게 높은 이자를 내고 있는 분 2.월 불입금을 줄이고 하시는 분 ...\n",
            "1503    (광고)(광고)자격조건1.만20세65세까지2.직장인사업자일용직주부학생3.최근부결자 ...\n",
            "1504    (광고)신용등급관리팀에서 등급올릴수 있는 tip 알려드립니다.1.주거래 은행만들기은...\n",
            "1505    (광고)(광고)-통합전환상품1. 채무과다로 인해 추가자금필요 혹은 채무통합을 원하시...\n",
            "Name: text, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImWh42AHrPK-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 라벨과 텍스트 각각 추출\n",
        "sentences = list(train[\"text\"].values)\n",
        "labels =list(train['smishing'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6ry0Xb0F_Hn",
        "colab_type": "text"
      },
      "source": [
        "## 2. Tokenization</br> \n",
        "options</br>\n",
        "1. WordPiece Tokenizer\n",
        "    - Tokenizer from Bert \n",
        "2. Okt Tokenizer (Previously Twitter) - UNK 너무 많음 \n",
        "    - morpheme tokenization \n",
        "3. Kkma Tokenizer  - 시간 너무 오래걸림 \n",
        "    - morpheme tokenization \n",
        "4. Mecab Tokenizer \n",
        "    - Colab 에서 사용 가능하게 install 하는 과정 필요 \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IM1MhIGemu6-",
        "colab_type": "code",
        "outputId": "9c01f8ae-99e5-4a03-d9ae-98606af1952c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "#1. Bert WordPiece Tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
        "tokenized_texts_wp = [tokenizer.tokenize(sen) for sen in sentences]\n",
        "\n",
        "print(sentences[0])\n",
        "print(tokenized_texts_wp[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "항상거래감사드립니다 봄햇살느끼며 오늘도 행복한하루 보내세요-과장\n",
            "['항', '##상', '##거', '##래', '##감', '##사', '##드', '##립', '##니다', '봄', '##햇', '##살', '##느', '##끼', '##며', '오', '##늘', '##도', '행', '##복', '##한', '##하', '##루', '보', '##내', '##세', '##요', '-', '과', '##장']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mF2uStRfArhc",
        "colab_type": "text"
      },
      "source": [
        "*Bert Tokenizer* </br>\n",
        "\n",
        "\n",
        "```\n",
        "항상거래감사드립니다 봄햇살느끼며 오늘도 행복한하루 보내세요-과장 </br> \n",
        "['항', '##상', '##거', '##래', '##감', '##사', '##드', '##립', '##니다', '봄', '##햇', '##살', '##느', '##끼', '##며', '오', '##늘', '##도', '행', '##복', '##한', '##하', '##루', '보', '##내', '##세', '##요', '-', '과', '##장']\n",
        "```\n",
        "\n",
        "\n",
        "</br> *그냥 한단어씩 다 자르는 듯.. corpus 부족*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAzHk8f-JwYc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # #2. Okt Tokenizer \n",
        "# from konlpy.tag import Okt  \n",
        "# okt=Okt()  \n",
        "# tokenized_texts = [okt.morphs(sen) for sen in sentences]\n",
        "\n",
        "# print(sentences[0])\n",
        "# print(tokenized_texts[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JRvy3U62yZU",
        "colab_type": "text"
      },
      "source": [
        "*Okt tokenizer*\n",
        "```\n",
        "항상거래감사드립니다 봄햇살느끼며 오늘도 행복한하루 보내세요-과장\n",
        "['항상', '거래', '감사', '드립니다', '봄', '햇살', '느끼며', '오늘', '도', '행복한', '하루', '보내세요', '-', '과장']\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8boEqSNYKXfg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #3. 꼬꼬마 Tokenizer \n",
        "# from konlpy.tag import Kkma  \n",
        "# kkma=Kkma()  \n",
        "# tokenized_texts_kkma = [kkma.morphs(sen) for sen in sentences]\n",
        "\n",
        "\n",
        "# print(sentences[0])\n",
        "# print(tokenized_texts_kkma[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nYrdFLE_oVW",
        "colab_type": "code",
        "outputId": "abea86e2-3fac-46c9-9f4e-d3edc1c80d1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#4. Mecab Tokenizer\n",
        "from konlpy.tag import Mecab\n",
        "mecab = Mecab()\n",
        "tokenized_texts_mc = [mecab.morphs(sen) for sen in sentences]\n",
        "\n",
        "print(sentences[0])\n",
        "print(tokenized_texts_mc[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "항상거래감사드립니다 봄햇살느끼며 오늘도 행복한하루 보내세요-과장\n",
            "['항상', '거래', '감사', '드립니다', '봄', '햇살', '느끼', '며', '오늘', '도', '행복', '한', '하루', '보내', '세요', '-', '과장']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoZuumyWvyKV",
        "colab_type": "text"
      },
      "source": [
        "# 3. Preprocessing Text \n",
        "####1) Remove Stopwords</br>\n",
        "####2) Insert [CLS], [SEP]</br>\n",
        "####3)  Shorten Texts to a Fixed Length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxapbM3dn83y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stopword(s): \n",
        "    for wrds in removewords:\n",
        "        wrds = \"\".join(wrds)\n",
        "        for i in s:\n",
        "            if (i==wrds):\n",
        "                s.remove(i)\n",
        "    return s\n",
        "\n",
        "\n",
        "def cut(s): \n",
        "    if len(s) > 30: \n",
        "        s = s[:30]\n",
        "    return s "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVYNVi4YuVMR",
        "colab_type": "code",
        "outputId": "5c11bcbc-83ff-491d-c062-46e94dbd32c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#1)Remove Stopwords\n",
        "sentences_swremoved= list(map(lambda sen: stopword(sen),tokenized_texts_mc))\n",
        "sentences_swremoved[:3]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['항상', '거래', '봄', '햇살', '느끼', '오늘', '행복', '하루', '보내'],\n",
              " ['소중', '거래', '매우', '동의', '부탁'],\n",
              " ['밝', '미소', '사랑', '가득', '하루', '보내', '벤처', '밸리']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txKoX7O_neLs",
        "colab_type": "code",
        "outputId": "f34f6144-5ae4-4b62-ea10-51c1ef25153a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "sentence_preprocessed = list(map(lambda tokens: cut(tokens),sentences_swremoved))\n",
        "sentence_preprocessed[:3]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['항상', '거래', '봄', '햇살', '느끼', '오늘', '행복', '하루', '보내'],\n",
              " ['소중', '거래', '매우', '동의', '부탁'],\n",
              " ['밝', '미소', '사랑', '가득', '하루', '보내', '벤처', '밸리']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r12woMVC6lVn",
        "colab_type": "text"
      },
      "source": [
        "#4. Embedding \n",
        "- input ids\n",
        "- padding\n",
        "- split into train ids and validation ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZsiBaUfW4ou",
        "colab_type": "text"
      },
      "source": [
        "*attention_mask is not required for BertModel*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dTW6wU5tgeP",
        "colab_type": "code",
        "outputId": "4a72b9f7-0dd2-44c2-b64d-9a59ccc0e4b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "#bert 인풋 형식 맞게 input_ids 만들어줌 \n",
        "#input_ids : embedding + padding \n",
        "max_len = 0\n",
        "for txt in sentence_preprocessed:\n",
        "    if max_len < len(txt): \n",
        "        max_len = len(txt)\n",
        "\n",
        "\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(tokens) for tokens in sentence_preprocessed]\n",
        "input_ids = pad_sequences(input_ids, maxlen = max_len, dtype = 'long', truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print(max_len)\n",
        "print(input_ids[23])\n",
        "print(input_ids.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n",
            "[ 100  100  100  100 9685  100  100    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0]\n",
            "(3000, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WE09XxvC0Nf0",
        "colab_type": "code",
        "outputId": "359e7643-6ffb-4362-f2d4-19a90f0a042b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "print(tokenizer.convert_tokens_to_ids('[CLS]'))\n",
        "print(tokenizer.convert_tokens_to_ids('[SEP]'))\n",
        "print(tokenizer.convert_tokens_to_ids('[UNK]'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "101\n",
            "102\n",
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OU1z2-h7vxE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # attention_mask : 1 if not padded, 0 if padded \n",
        "\n",
        "# def masking(d):\n",
        "#     masklist = []\n",
        "#     for e in d:\n",
        "#         if float(e)!=0:\n",
        "#             masklist.append(1)\n",
        "#         else:\n",
        "#             masklist.append(0)\n",
        "#     return masklist\n",
        "# attention_mask = list(map(lambda seq : masking(seq), input_ids))\n",
        "\n",
        "\n",
        "# print(attention_mask[0])        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FkGYQMlxbV_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train, test split \n",
        "train_id, validation_id,train_label, validation_label = train_test_split(input_ids, labels, test_size = 0.2, random_state = 1010, shuffle= True)\n",
        "# train_att_mask, validation_att_mask, _, _ = train_test_split(attention_mask, input_ids, test_size = 0.1, random_state = 1010, shuffle= False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxzxqnfIDy51",
        "colab_type": "code",
        "outputId": "8a149d6b-78db-4df8-fada-43fcc7fdfcca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "print(train_id[0])\n",
        "print(train_id.shape)\n",
        "print(validation_id.shape)\n",
        "#왜 101이 사라지는지?  마지막부분 문장끝만 확인이 필요해서 임의로 지워지나 ? "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  100   100   100 98151 10413   100   100   100   100   100  9555   100\n",
            "   100   100   100   100  9248   100   100  9157   100   100   100  9555\n",
            "   100   100   100   100   100  9521]\n",
            "(2400, 30)\n",
            "(600, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wplrpHuyIfc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_id = torch.tensor(train_id)\n",
        "validation_id = torch.tensor(validation_id)\n",
        "train_label = torch.tensor(train_label)\n",
        "validation_label = torch.tensor(validation_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wO7aJ957zi6-",
        "colab_type": "code",
        "outputId": "52a8d49e-1708-4320-d5a5-8c0f4b9dadbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "print(train_id[0])\n",
        "print(train_label[0])\n",
        "print(validation_id[0])\n",
        "print(validation_label[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([  100,   100,   100, 98151, 10413,   100,   100,   100,   100,   100,\n",
            "         9555,   100,   100,   100,   100,   100,  9248,   100,   100,  9157,\n",
            "          100,   100,   100,  9555,   100,   100,   100,   100,   100,  9521])\n",
            "tensor(1)\n",
            "tensor([  100,   100,   100,  9531,   100,   100,   100,   100,   100,   100,\n",
            "         9322,  9279,  9663,   100,   100,   100, 25701,   100, 42608,   100,\n",
            "        31613,  9251,     0,     0,     0,     0,     0,     0,     0,     0])\n",
            "tensor(0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yH9Z_PWaZNaR",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "*BertModel*\n",
        "\n",
        "*( \"The bare Bert Model transformer outputting raw hidden-states without any specific head on top.\")*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMkHa71JXww0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_model = BertModel.from_pretrained('bert-base-multilingual-cased')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHXPRBdZEhIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "    x_train = bert_model(train_id)[0]\n",
        "    x_val = bert_model(validation_id)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGLH_1CxZ4W-",
        "colab_type": "code",
        "outputId": "9537c0b1-7b6a-49bf-9df2-3b44f6359724",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "y_train = train_label.float().unsqueeze(1)\n",
        "y_val = validation_label.float().unsqueeze(1) \n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2400, 30, 768])\n",
            "torch.Size([2400, 1])\n",
            "torch.Size([600, 30, 768])\n",
            "torch.Size([600, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGk-A-393vrR",
        "colab_type": "text"
      },
      "source": [
        "#5. Dataset Preprocessing - Testing set (Skipped) \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvGGFwtt3fPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sentences = test['text']\n",
        "\n",
        "# sentences_preprocess = list(map(lambda sen: cut(stopword(str(sen))),sentences))\n",
        "# sentences_ = list(map(lambda sen:'[CLS]' + str(sen) + '[SEP]' , sentences_preprocess))\n",
        "\n",
        "# tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
        "# tokenized_texts = [tokenizer.tokenize(sen) for sen in sentences_]\n",
        "\n",
        "# max_len = 22\n",
        "# input_ids = [tokenizer.convert_tokens_to_ids(tokens) for tokens in tokenized_texts]\n",
        "# input_ids = pad_sequences(input_ids, maxlen = max_len, dtype = 'long', truncating=\"post\", padding=\"post\")\n",
        "\n",
        "\n",
        "# print(sentences_[0])\n",
        "# print(tokenized_texts[0])\n",
        "# print(input_ids[0])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiX2qWTR37c0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test_input = torch.tensor(input_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJCzgSLc6iJE",
        "colab_type": "text"
      },
      "source": [
        "# 6. Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1svpujvcBHy4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size,dropout, bidirectional, num_layers,num_classes = 1):\n",
        "        super(RNN,self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.dropout = dropout\n",
        "        self.num_layers = num_layers\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        if bidirectional:\n",
        "            hidden_size /=2\n",
        "        self.rnn = nn.RNN(input_size = self.input_size, \n",
        "                          hidden_size = self.hidden_size, \n",
        "                          num_layers = num_layers, \n",
        "                          dropout = dropout, \n",
        "                          bidirectional = bidirectional,\n",
        "                          batch_first = True)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    \n",
        "    def forward(self,x):\n",
        "        \"\"\"\n",
        "        Args: \n",
        "            input = (Batch, seq_len, input size <-- meaning embedded size?)\n",
        "        Return:\n",
        "            Output = (Batch, seq_len, num_dir * hidden size)\n",
        "        \"\"\"\n",
        "        h0 =  torch.zeros(self.num_layers,x.shape[0],self.hidden_size)\n",
        "        output, _ = self.rnn(x,h0) #output : torch.Size([20, 30, 256]), hidden : torch.Size([1, 20, 256])\n",
        "        out = self.fc(output[:, -1, :])\n",
        "        out = self.sigmoid(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44UKE1sRBP6o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_size = x_train.shape[2] # dimension of input embedding \n",
        "hidden_size = 256\n",
        "dropout = 0 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hc5dua9uDaHA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = RNN(input_size = input_size, \n",
        "            hidden_size = hidden_size,\n",
        "            dropout = dropout, \n",
        "            bidirectional = False,\n",
        "            num_layers = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-N5hdDnJFed9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_batch_data(x, y, batch_size):\n",
        "    i, batch = 0, 0\n",
        "    for batch, i in enumerate(range(0, len(x) - batch_size, batch_size), 1):\n",
        "        x_batch = x[i : i + batch_size]\n",
        "        y_batch = y[i : i + batch_size]\n",
        "        yield x_batch, y_batch, batch\n",
        "    if i + batch_size < len(x):\n",
        "        yield x[i + batch_size :], y[i + batch_size :], batch + 1\n",
        "    if batch == 0:\n",
        "        yield x, y, 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYl6BDhGHCKI",
        "colab_type": "code",
        "outputId": "5cb76916-04f2-4b53-a6d4-0a867b555a13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "n_epochs = 3\n",
        "train_losses, val_losses = [], []\n",
        "batch_size = 20\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    start_time = time.time()\n",
        "    train_loss = 0\n",
        "    train_accuracy = 0\n",
        "    test_accuracy = 0\n",
        "    batch_train_accuracy = []\n",
        "    batch_test_accuracy = []\n",
        "    model.train(True)\n",
        "    for x_batch, y_batch, batch in generate_batch_data(x_train, y_train, batch_size):\n",
        "        y_pred_label = []\n",
        "        y_pred = model(x_batch) #x_batch : (20,30,768) \n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        y_pred_label = np.where(y_pred>=0.5, 1, 0)\n",
        "        batch_train_accuracy.append(accuracy_score(y_pred_label,y_batch.numpy()))\n",
        "\n",
        "        loss = loss_fn(y_pred,y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    \n",
        "    train_accuracy = sum(batch_train_accuracy) / batch \n",
        "    train_loss /= batch\n",
        "    train_losses.append(train_loss)\n",
        "    elapsed = time.time() - start_time\n",
        "\n",
        "\n",
        "    \n",
        "    model.eval() # disable dropout for deterministic output\n",
        "    with torch.no_grad(): # deactivate autograd engine to reduce memory usage and speed up computations\n",
        "        val_loss, batch = 0, 1\n",
        "\n",
        "        for x_batch, y_batch, batch in generate_batch_data(x_val, y_val, batch_size):\n",
        "            y_pred_label = []\n",
        "            y_pred = model(x_batch)\n",
        "            loss = loss_fn(y_pred, y_batch)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            \n",
        "            y_pred_label = np.where(y_pred>=0.5, 1, 0)\n",
        "            batch_test_accuracy.append(accuracy_score(y_pred_label,y_batch.numpy()))\n",
        "            \n",
        "        val_loss /= batch\n",
        "        val_losses.append(val_loss)\n",
        "        test_accuracy = sum(batch_test_accuracy)/ batch\n",
        "\n",
        "    print(\n",
        "        \"Epoch %d Train loss: %.2f. Validation loss: %.2f. Elapsed time: %.2fs. Accuracy in Training: %.3f. Accuracy in Testing : %.3f\"\n",
        "        % (epoch + 1, train_losses[-1], val_losses[-1], elapsed, train_accuracy, test_accuracy)\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Train loss: 0.23. Validation loss: 0.15. Elapsed time: 2.25s. Accuracy in Training: 0.905. Accuracy in Testing : 0.935\n",
            "Epoch 2 Train loss: 0.13. Validation loss: 0.14. Elapsed time: 2.17s. Accuracy in Training: 0.950. Accuracy in Testing : 0.945\n",
            "Epoch 3 Train loss: 0.10. Validation loss: 0.12. Elapsed time: 2.12s. Accuracy in Training: 0.966. Accuracy in Testing : 0.952\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0QjqQ0m4Eqh",
        "colab_type": "code",
        "outputId": "7bcfb3f4-69df-437a-98c1-96577520c01c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "plt.plot(train_losses, label=\"Training loss\")\n",
        "plt.plot(val_losses, label=\"Validation loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Losses\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Losses')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guRyg1Oy9iM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/pytorch/captum.git\n",
        "!cd captum; pip install -e ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFm-T9t9_Ek7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "import torch\n",
        "\n",
        "from captum.attr import IntegratedGradients\n",
        "from captum.attr import LayerConductance\n",
        "from captum.attr import NeuronConductance\n",
        "\n",
        "token_reference = TokenReferenceBase(reference_token_idx = input_ids)\n",
        "lig = LayerIntegratedGradients(model, model.embedding)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfersPyB_a-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
